# Apache Airflow Example
This repository aims to provide an end to end example of [Apache Airflow](http://airflow.apache.org/index.html) for developers who are unfamiliar with it. Apache Airflow is a platform to programmatically author, schedule, and monitor workflows. Engineers can use airflow to create DAGs that execute tasks and visualize the pipeline.  


## Requirements
- Basic Knowledge of Python
- Linux VM 
- Anaconda Installation


## Blog
This demo is accompanied with a [blog]() discussing why data engineers and data scientists should use Apache Airflow to schedule, monitor, orchestrate, and create data pipelines. 


## Demo
The demo is broken into logical sections. Please complete in the following order:  
1. [Create Ubuntu VM](https://ryansdataspot.com/2019/05/07/linux-development-from-a-windows-guy/)
    - Note, I will be using a Hyper-V Virtual Machine on my local computer

1. [Configure workspace](./Docs/02_ConfigureWorkspace.md) 

1. [Create Hello World DAG](./Docs/03_HelloWorld.md)

1. [Simple Data Pipeline with Airflow](./Docs/04_AirflowPipeline.md)

1. [Deploying Data Pipelines to Azure](./Docs/05_DeployingDataPipelines.md)

